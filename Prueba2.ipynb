{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdB6BNWFLW1qd4tv2pbGbm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rociohbarroso/Python/blob/main/Prueba2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "EIP1__R7TxIj",
        "outputId": "fcfc1261-85aa-41a6-ef70-3c70c5a82a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-acb7b45a7ecf>\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgunas_imagenes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "#pip install tensorflow\n",
        "#pip install keras\n",
        "#pip install imgaug\n",
        "#pip install opencv-python\n",
        "#pip install h5py\n",
        "#pip install tqdm\n",
        "#pip install imutils\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "import copy\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.utils import Sequence\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "import os\n",
        "imagenes_path = \"/imagenes\"\n",
        "anotaciones_path=\"/anotaciones\"\n",
        "\n",
        "trainval = open(os.path.join(anotaciones_path,\"documento.xml\")).readlines()\n",
        "os.makedirs(os.path.join(imagenes_path,\"train\",\"lubinas\"), exist_ok=True)\n",
        "\n",
        "def classify_image(line, subset):\n",
        "  basename = line.split(\" \")[0]\n",
        "  species = line.split(\" \")[2]\n",
        "  oldpath = os.path.join(imagenes_path, f\"{basename}.jpg\")\n",
        "  newpath = os.path.join(imagenes_path, subset, f\"{basename}.jpg\")\n",
        "  if os.path.isfile(oldpath):\n",
        "        os.rename(oldpath, newpath)\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "generador_entrenamiento = ImageDataGenerator()\n",
        "datos_entrenamiento = generador_entrenamiento.flow_from_directory(\"/imagenes/\")\n",
        "generador_test = ImageDataGenerator()\n",
        "datos_test = generador_test.flow_from_directory(\"/imagenes/\", class_mode=None)\n",
        "algunas_imagenes = next(datos_test)\n",
        "\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(algunas_imagenes[0]/255.)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import applications\n",
        "inception = applications.InceptionV3(include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "predictor = Sequential([\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])\n",
        "modelo = Sequential([inception, predictor])\n",
        "modelo.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
        "\n",
        "modelo.fit(datos_entrenamiento, epochs=1)\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "  intersect_w = _interval_overlap([box1.xmin, box1.max], [box2.xmin, box2.max])\n",
        "  intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.yax])\n",
        "\n",
        "  intersect = intersect_w * intersect_h\n",
        "\n",
        "  w1,h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "  w2,h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "  union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "  return float(intersect) / union\n",
        "\n",
        "class BoundBox:\n",
        "  def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "    self.xmin = xmin\n",
        "    self.ymin = ymin\n",
        "    self.xmax = xmax\n",
        "    self.ymax = ymax\n",
        "    self.c = c\n",
        "    self.classes = classes\n",
        "    self.label = -1\n",
        "    self.score = -1\n",
        "\n",
        "  def get_label(self):\n",
        "    if self.label == -1:\n",
        "      self.label = np.argmax(self.classes)\n",
        "    return self.label\n",
        "\n",
        "  def get_score(self):\n",
        "    if self.score == -1:\n",
        "      self.core = self.classes[self.get_label()]\n",
        "    return self.score\n",
        "\n",
        "class BatchGenerator(Sequence):\n",
        "  def __init__(self, images, config, shuffle=True, jitter=True, norm=None):\n",
        "    self.generator = None\n",
        "    self.images = images\n",
        "    self.config = config\n",
        "    self.shuffle = shuffle\n",
        "    self.jitter = jitter\n",
        "    self.norm = norm\n",
        "    self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\n",
        "\n",
        "    sometimes = lambda aug : iaa.Sometimes(0.5,aug)\n",
        "\n",
        "    self.aug_pipe = iaa.Sequential(\n",
        "        [\n",
        "            sometimes(iaa.Affine()),\n",
        "            iaa.SomeOf((0,5),\n",
        "                [\n",
        "                    iaa.OneOf([\n",
        "                        iaa.GaussianBlur((0, 3.0)),\n",
        "                        iaa.AverageBlur(k=(2,7)),\n",
        "                        iaa.MedianBlur(k=(3,11)),\n",
        "                    ]),\n",
        "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
        "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0,0.05*255),per_channel=0.5),\n",
        "                    iaa.OneOf([\n",
        "                        iaa.Dropout((0.01,0.1), per_channel=0.5),\n",
        "                    ]),\n",
        "                    iaa.Add((-10,10), per_channel=0.5),\n",
        "                    iaa.Multiply((0.5,1.5), per_channel=0.5),\n",
        "                    iaa.ContrastNormalization((0.5,2.0), per_channel= 0.5),\n",
        "                ],\n",
        "                random_order = True\n",
        "            )\n",
        "        ],\n",
        "        random_order = True\n",
        "    )\n",
        "    if shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.cel(float(len(self.images))/self.config['BATCH_SIZE']))\n",
        "\n",
        "  def num_classes(self):\n",
        "    return len(self.config['LABELS'])\n",
        "\n",
        "  def size(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def load_annotation(self, i):\n",
        "    annots = []\n",
        "\n",
        "    for obj in self.images[i]['object']:\n",
        "      annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.config['LABELS'].index(obj['name'])]\n",
        "      annots += [annot]\n",
        "\n",
        "    if len(annots) == 0: annots = [[]]\n",
        "    return np.array(annots)\n",
        "\n",
        "  def load_images(self, i):\n",
        "    return cv2.imread(self.images[i]['filename'])\n",
        "\n",
        "  def __getitem___(self, idx):\n",
        "    l_bound = idx*self.config['BATCH_SIZE']\n",
        "    r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
        "\n",
        "    if r_bound > len(self.images):\n",
        "      r_bound = len(self.images)\n",
        "      l_bound = r_bound - self.config['BATCH_SIZE']\n",
        "\n",
        "    instance_count = 0\n",
        "\n",
        "    x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_W'],3))\n",
        "    b_batch = np.zeros((r_bound-l_bound, 1, 1, 1, self.config['TRUE_BOX_BUFFER'],4))\n",
        "    y_batch = np.zeros((r_bound-l_bound, self.config['GRID_H'], self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))\n",
        "\n",
        "    for train_instance in self.images[l_bound:r_bound]:\n",
        "      img,all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
        "      true_box_index = 0\n",
        "\n",
        "      for obj in all_objs:\n",
        "        if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
        "              center_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "              center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
        "              center_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "              center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
        "\n",
        "              grid_x = int(np.floor(center_x))\n",
        "              grid_y = int(np.floor(center_y))\n",
        "\n",
        "              if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
        "                obj_indx = self.config['LABELS'].index(obj['name'])\n",
        "\n",
        "                center_w = (obj['xmax']-obj['xmin'])/(float(self.config['IMAGE_W'])/ self.config['GRID_W'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}