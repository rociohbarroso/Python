{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/rociohbarroso/Python/blob/main/Prueba_Lego.ipynb",
      "authorship_tag": "ABX9TyOeUK9VDLxaMYbp9zLVlhXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rociohbarroso/Python/blob/main/Prueba_Lego.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y1h0-S6ha0hk",
        "outputId": "d964b1af-e0a1-48c6-c578-45c52c4383de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.0.8\n",
            "    Uninstalling Keras-2.0.8:\n",
            "      Successfully uninstalled Keras-2.0.8\n",
            "Successfully installed keras-2.15.0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from imgaug) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.11.0->imgaug) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.11.0->imgaug) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.11.0->imgaug) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.11.0->imgaug) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.11.0->imgaug) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.11.0->imgaug) (24.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow\n",
        "%pip install keras\n",
        "%pip install imgaug\n",
        "%pip install opencv-python\n",
        "%pip install h5py\n",
        "%pip install tqdm\n",
        "%pip install imutils\n",
        "\n",
        "import argparse\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "import copy\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from keras.utils import Sequence\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "\n",
        "imagenes_path = \"drive/MyDrive/Legos/LEGO/images/lego4/\"\n",
        "anotaciones_path=\"drive/MyDrive/Legos/LEGO/annotation/lego4/\"\n",
        "labels = \"lego\"\n",
        "tamanio = 416\n",
        "def leer_annotations(ann_dir, img_dir, labels=[]):\n",
        "        all_imgs = []\n",
        "        seen_labels = {}\n",
        "\n",
        "        for ann in [x for x in sorted(os.listdir(ann_dir)) if x.endswith('.xml')] :\n",
        "            img = {'object':[]}\n",
        "\n",
        "            tree = ET.parse(ann_dir + ann)\n",
        "\n",
        "            for elem in tree.iter():\n",
        "                if 'filename' in elem.tag:\n",
        "                    img['filename'] = img_dir + elem.text\n",
        "                if 'width' in elem.tag:\n",
        "                    img['width'] = int(elem.text)\n",
        "                if 'height' in elem.tag:\n",
        "                    img['height'] = int(elem.text)\n",
        "                if 'object' in elem.tag or 'part' in elem.tag:\n",
        "                    obj = {}\n",
        "                    for attr in list(elem):\n",
        "                        if 'name' in attr.tag:\n",
        "                            obj['name'] = attr.text\n",
        "\n",
        "                            if obj['name'] in seen_labels:\n",
        "                               seen_labels[obj['name']] += 1\n",
        "                            else:\n",
        "                                seen_labels[obj['name']] = 1\n",
        "\n",
        "                            if len(labels) > 0 and obj['name'] not in labels:\n",
        "                                break\n",
        "                            else:\n",
        "                                img['object'] += [obj]\n",
        "\n",
        "                        if 'bndbox' in attr.tag:\n",
        "                            for dim in list(attr):\n",
        "                                if 'xmin' in dim.tag:\n",
        "                                    obj['xmin'] = int(round(float(dim.text)))\n",
        "                                if 'ymin' in dim.tag:\n",
        "                                    obj['ymin'] = int(round(float(dim.text)))\n",
        "                                if 'xmax' in dim.tag:\n",
        "                                    obj['xmax'] = int(round(float(dim.text)))\n",
        "                                if 'ymax' in dim.tag:\n",
        "                                   obj['ymax'] = int(round(float(dim.text)))\n",
        "\n",
        "            if len(img['object']) > 0:\n",
        "               all_imgs += [img]\n",
        "\n",
        "        return all_imgs, seen_labels\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_imgs, train_labels = leer_annotations(anotaciones_path, imagenes_path, labels)\n",
        "print('imagenes',len(train_imgs), 'labels',len(train_labels))\n",
        "train_valid_split = int(0.8*len(train_imgs))\n",
        "np.random.shuffle(train_imgs)\n",
        "valid_imgs = train_imgs[train_valid_split:]\n",
        "train_imgs = train_imgs[:train_valid_split]\n",
        "print('train:',len(train_imgs), 'validate:',len(valid_imgs))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AuHiYXzOTrLD",
        "outputId": "af13cb25-0133-464d-b2f7-4b2e2b7bbefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imagenes 323 labels 1\n",
            "train: 258 validate: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "  intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "  intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "  intersect = intersect_w * intersect_h\n",
        "\n",
        "  w1,h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "  w2,h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "  union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "  return float(intersect) / union\n"
      ],
      "metadata": {
        "id": "CRk6G6NcUpU6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BoundBox:\n",
        "  def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "    self.xmin = xmin\n",
        "    self.ymin = ymin\n",
        "    self.xmax = xmax\n",
        "    self.ymax = ymax\n",
        "    self.c = c\n",
        "    self.classes = classes\n",
        "    self.label = -1\n",
        "    self.score = -1\n",
        "\n",
        "  def get_label(self):\n",
        "    if self.label == -1:\n",
        "      self.label = np.argmax(self.classes)\n",
        "    return self.label\n",
        "\n",
        "  def get_score(self):\n",
        "    if self.score == -1:\n",
        "      self.score = self.classes[self.get_label()]\n",
        "    return self.score\n",
        "\n"
      ],
      "metadata": {
        "id": "MiyPVJfDVI6S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchGenerator(Sequence):\n",
        "  def __init__(self, images, config, shuffle=True, jitter=True, norm=None):\n",
        "    self.generator = None\n",
        "    self.images = images\n",
        "    self.config = config\n",
        "    self.shuffle = shuffle\n",
        "    self.jitter = jitter\n",
        "    self.norm = norm\n",
        "    self.anchors = [BoundBox(0, 0, config['ANCHORS'][2*i], config['ANCHORS'][2*i+1]) for i in range(int(len(config['ANCHORS'])//2))]\n",
        "\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "    self.aug_pipe = iaa.Sequential(\n",
        "        [\n",
        "            sometimes(iaa.Affine()),\n",
        "            iaa.SomeOf((0,5),\n",
        "                [\n",
        "                    iaa.OneOf([\n",
        "                        iaa.GaussianBlur((0, 3.0)),\n",
        "                        iaa.AverageBlur(k=(2, 7)),\n",
        "                        iaa.MedianBlur(k=(3, 11)),\n",
        "                    ]),\n",
        "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
        "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0,0.05*255),per_channel=0.5),\n",
        "                    iaa.OneOf([\n",
        "                        iaa.Dropout((0.01,0.1), per_channel=0.5),\n",
        "                    ]),\n",
        "                    iaa.Add((-10,10), per_channel=0.5),\n",
        "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
        "                    iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "    )\n",
        "    if shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))\n",
        "\n",
        "  def num_classes(self):\n",
        "    return len(self.config['LABELS'])\n",
        "\n",
        "  def size(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def load_annotation(self, i):\n",
        "    annots = []\n",
        "    for obj in self.images[i]['object']:\n",
        "      annot = [obj['xmin'], obj['ymin'], obj['xmax'], obj['ymax'], self.config['LABELS'].index(obj['name'])]\n",
        "      annots += [annot]\n",
        "\n",
        "    if len(annots) == 0: annots = [[]]\n",
        "\n",
        "    return np.array(annots)\n",
        "\n",
        "  def load_image(self, i):\n",
        "    return cv2.imread(self.images[i]['filename'])\n",
        "\n",
        "  def __getitem___(self, idx):\n",
        "    l_bound = idx*self.config['BATCH_SIZE']\n",
        "    r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
        "\n",
        "    if r_bound > len(self.images):\n",
        "      r_bound = len(self.images)\n",
        "      l_bound = r_bound - self.config['BATCH_SIZE']\n",
        "\n",
        "    instance_count = 0\n",
        "\n",
        "    x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'],3))\n",
        "    b_batch = np.zeros((r_bound - l_bound, 1, 1, 1, self.config['TRUE_BOX_BUFFER'],4))\n",
        "    y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'], self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))\n",
        "\n",
        "    for train_instance in self.images[l_bound:r_bound]:\n",
        "      img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
        "      true_box_index = 0\n",
        "\n",
        "      for obj in all_objs:\n",
        "        if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
        "              center_x = .5*(obj['xmin'] + obj['xmax'])\n",
        "              center_x = center_x / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
        "              center_y = .5*(obj['ymin'] + obj['ymax'])\n",
        "              center_y = center_y / (float(self.config['IMAGE_H']) / self.config['GRID_H'])\n",
        "\n",
        "              grid_x = int(np.floor(center_x))\n",
        "              grid_y = int(np.floor(center_y))\n",
        "\n",
        "              if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
        "                obj_indx = self.config['LABELS'].index(obj['name'])\n",
        "\n",
        "                center_w = (obj['xmax'] - obj['xmin']) / (float(self.config['IMAGE_W']) / self.config['GRID_W'])\n",
        "                center_h = (obj['ymax'] - obj['ymin']) / (float(self.config['IMAGE_H']) / self.config['GRID_H']) # unit: grid cell\\n\",\n",
        "\n",
        "                box = [center_x, center_y, center_w, center_h]\n",
        "\n",
        "                best_anchor = -1\n",
        "                max_iou     = -1\n",
        "\n",
        "                shifted_box = BoundBox(0, 0, center_w, center_h)\n",
        "\n",
        "                for i in range(len(self.anchors)):\n",
        "                  anchor = self.anchors[i]\n",
        "                  iou    = bbox_iou(shifted_box, anchor)\n",
        "\n",
        "                  if max_iou < iou:\n",
        "                   best_anchor = i\n",
        "                   max_iou     = iou\n",
        "\n",
        "                # assign ground truth x, y, w, h, confidence and class probs to y_batch\\n\",\n",
        "                y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box\n",
        "                y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1.\n",
        "                y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1\n",
        "\n",
        "                # assign the true box to b_batch\\n\",\n",
        "                b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
        "\n",
        "                true_box_index += 1\n",
        "                true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
        "\n",
        "      # assign input image to x_batch\\n\",\n",
        "      if self.norm != None:\n",
        "        x_batch[instance_count] = self.norm(img)\n",
        "      else:\n",
        "        # plot image and bounding boxes for sanity check\\n\",\n",
        "        for obj in all_objs:\n",
        "         if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin']:\n",
        "          cv2.rectangle(img[:,:,::-1], (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (255,0,0), 3)\n",
        "          cv2.putText(img[:,:,::-1], obj['name'], (obj['xmin']+2, obj['ymin']+12), 0, 1.2e-3 * img.shape[0], (0,255,0), 2)\n",
        "\n",
        "        x_batch[instance_count] = img\n",
        "\n",
        "      # increase instance counter in current batch\\n\",\n",
        "      instance_count += 1\n",
        "\n",
        "     #print(' new batch created', idx)\\n\",\n",
        "\n",
        "    return [x_batch, b_batch], y_batch\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle: np.random.shuffle(self.images)\n",
        "\n",
        "  def aug_image(self, train_instance, jitter):\n",
        "    image_name = train_instance['filename']\n",
        "    image = cv2.imread(image_name)\n",
        "\n",
        "    if image is None: print ('Cannot find', image_name)\n",
        "\n",
        "    h, w,c = image.shape\n",
        "    all_objs = copy.deepcopy(train_instance['object'])\n",
        "\n",
        "    if jitter:\n",
        "      ##scale the image\n",
        "      scale = np.random.uniform() /10. +1.\n",
        "      image = cv2.resize(image, (0,0), fx = scale, fy = scale)\n",
        "\n",
        "      ## translate the image\n",
        "      max_offx = (scale-1.) * w\n",
        "      max_offy =(scale-1.)*h\n",
        "      offx = int(np.random.uniform()* max_offx)\n",
        "      offy = int(np.random.uiform() * max_offy)\n",
        "\n",
        "      image = image[offy : (offy + h), offx : (offx + w)]\n",
        "\n",
        "      ##flip the image\n",
        "      flip = np.random.binomial(1, .5)\n",
        "      if flip > 0.5: image = cv2.flip(image, 1)\n",
        "\n",
        "      image = self.aug_pipe.augment_image(image)\n",
        "\n",
        "    ##resize the image to standard size\n",
        "    image = cv2.resize(image, (self.config['IMAGE_H'], self.config['IMAGE_W']))\n",
        "    image = image[:,:,::-1]\n",
        "\n",
        "    #fix object's position and size\n",
        "    for obj in all_objs:\n",
        "      for attr in ['xmin', 'xmax']:\n",
        "        if jitter: obj[attr] = int(obj[attr] * scale - offx)\n",
        "\n",
        "        obj[attr] = int(obj[attr] * float(self.config['IMAGE_W'])/w)\n",
        "        obj[attr] = max(min(obj[attr], self.config['IMAGE_W']), 0)\n",
        "\n",
        "      for attr in ['ymin', 'ymax']:\n",
        "        if jitter: obj[attr] = int(obj[attr] * scale - offy)\n",
        "\n",
        "        obj[attr] = int(obj[attr] * float(self.config['IMAGE_H'])/h)\n",
        "        obj[attr] = max(min(obj[attr], self.config['IMAGE_H']), 0)\n",
        "\n",
        "      if jitter and flip > 0.5:\n",
        "        xmin = obj['xmin']\n",
        "        obj['xmin'] = self.config['IMAGE_W'] - obj['xmax']\n",
        "        obj['xmax'] = self.config['IMAGE_W'] - xmin\n",
        "\n",
        "    return image, all_objs\n",
        "\n"
      ],
      "metadata": {
        "id": "KtxZ6qF9WW3y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "FULL_YOLO_BACKEND_PATH = \"/content/drive/MyDrive/Legos/LEGO/full_yolo_backend.h5\"\n",
        "\n",
        "class BaseFeatureExtractor(object):\n",
        "       \"\\\"\\\"\\\"docstring for ClassName\\\"\\\"\\ \"\n",
        "\n",
        "       #to be defined in each subclass\n",
        "       def __init__(self, input_size):\n",
        "        raise NotImplementedError(\"error message\\ \" )\n",
        "\n",
        "       #to be define  in each class\n",
        "       def normalize(self, image):\n",
        "         raise NotImplementedError(\"error message\\ \")\n",
        "\n",
        "       def get_output_shape(self):\n",
        "         return self.feature_extractor.get_output_shape_at(-1)[1:3]\n",
        "\n",
        "       def extract(self, input_image):\n",
        "        return self.feature_extractor(input_image)\n"
      ],
      "metadata": {
        "id": "GN-I_db7YLZq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class FullYoloFeature(BaseFeatureExtractor):\n",
        "        \"\\\"\\\"\\\"docstring for ClassName\\\"\\\"\\ \"\n",
        "        def __init__(self, input_size):\n",
        "          input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "          #the function to implement the organization layer\n",
        "          def space_to_depth_x2(x):\n",
        "           return tf.nn.space_to_depth(x, block_size=2)\n",
        "\n",
        "          #Layer 1\n",
        "          x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "          x = BatchNormalization(name='norm_1')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "          x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "          #Layer 2\n",
        "          x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_2')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "          x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "          #Layer 3\n",
        "          x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_3')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 4\n",
        "          x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_4')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 5\n",
        "          x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_5')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "          x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "          #Layer 6\n",
        "          x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_6')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 7\n",
        "          x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_7')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 8\n",
        "          x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_8')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "          x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "          #Layer 9\n",
        "          x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_9')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 10\n",
        "          x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_10')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 11\n",
        "          x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_11')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 12\n",
        "          x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_12')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 13\n",
        "          x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_13')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          skip_connection = x\n",
        "\n",
        "          x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "          #Layer 14\n",
        "          x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_14')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 15\n",
        "          x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_15')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 16\n",
        "          x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_16')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 17\n",
        "          x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_17')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 18\n",
        "          x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_18')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 19\n",
        "          x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_19')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 20\n",
        "          x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_20')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          #Layer 21\n",
        "          skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "          skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "          skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "          skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "          x = concatenate([skip_connection, x])\n",
        "\n",
        "          #Layer 22\n",
        "          x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
        "          x = BatchNormalization(name='norm_22')(x)\n",
        "          x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "          self.feature_extractor = Model(input_image, x)\n",
        "          self.feature_extractor.load_weights(FULL_YOLO_BACKEND_PATH)\n",
        "\n",
        "        def normalize(self, image):\n",
        "          return image / 255.\n",
        "\n"
      ],
      "metadata": {
        "id": "CVfwwjeHYwbT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#funciones que necesitaremos\n",
        "def _sigmoid(x):\n",
        "  return 1./(1. + np.exp(-x))\n",
        "\n",
        "def _softmax(x, axis=-1, t=-100.):\n",
        "  x = x - np.max(x)\n",
        "\n",
        "  if np.min(x) < t:\n",
        "    x = x/np.min(x)*t\n",
        "\n",
        "  e_x = np.exp(x)\n",
        "\n",
        "  return e_x / e_x.sum(axis, keepdims=True)\n",
        "\n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "  x1, x2 = interval_a\n",
        "  x3, x4 = interval_b\n",
        "\n",
        "  if x3 < x1:\n",
        "    if x4< x1:\n",
        "      return 0\n",
        "    else:\n",
        "      return min(x2,x4) - x1\n",
        "  else:\n",
        "    if x2 < x3:\n",
        "      return 0\n",
        "    else:\n",
        "      return min(x2,x4) -x3\n",
        "\n",
        "def compute_overlap(a, b):\n",
        "\n",
        "  area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:,1])\n",
        "\n",
        "  iw = np.minimum(np.expand_dims(a[:,2], axis=1), b[:,2]) - np.maximum(np.expand_dims(a[:,0], 1), b[:,0])\n",
        "  ih = np.minimum(np.expand_dims(a[:,3], axis=1), b[:,3]) - np.maximum(np.expand_dims(a[:,1], 1), b[:, 1])\n",
        "\n",
        "  iw = np.maximum(iw, 0)\n",
        "  ih = np.maximum(ih, 0)\n",
        "\n",
        "  ua = np.expand_dims((a[:,2] - a[:, 0]) * (a[:,3] - a[:,1]), axis=1) + area - iw * ih\n",
        "\n",
        "  ua = np.maximum(ua, np.finfo(float).eps)\n",
        "\n",
        "  intersection = iw * ih\n",
        "\n",
        "  return intersection / ua\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "  #first append sentinel values at the end\n",
        "  mrec = np.concatenate(([0.], recall, [1.]))\n",
        "  mpre = np.concatenate(([0.], precision, [0.]))\n",
        "\n",
        "  #compute the precision envelope\n",
        "  for i in range(mpre.size - 1, 0, -1):\n",
        "    mpre[i - 1]= np.maximum(mpre[i -1], mpre[i])\n",
        "\n",
        "  #to calculate area under PR curve, look for points\n",
        "  #where X axis (recall) changes value\n",
        "  i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "  #and sum (\\\\Delta recall) * prec\n",
        "  ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "  return ap\n",
        "\n",
        "def decode_netout(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
        "  grid_h, grid_w, nb_box = netout.shape[:3]\n",
        "\n",
        "  boxes = []\n",
        "\n",
        "  #decode the output by the network\n",
        "  netout[...,4] = _sigmoid(netout[...,4])\n",
        "  netout[...,5:] = netout[...,4][..., np.newaxis] * _softmax(netout[...,5:])\n",
        "  netout[...,5:] *= netout[..., 5:] > obj_threshold\n",
        "  for row in range(grid_h):\n",
        "    for col in range(grid_w):\n",
        "      for b in range(nb_box):\n",
        "        #from 4th element onwards are confidence and class classes\n",
        "        classes = netout[row, col,b,5:]\n",
        "\n",
        "        if np.sum(classes) > 0:\n",
        "          #first 4 elements are x,y,w and h\n",
        "          x, y, w, h = netout[row, col, b, :4]\n",
        "\n",
        "          x = (col + _sigmoid(x)) / grid_w #center position, unit : image width\n",
        "          y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
        "          w = anchors[2 * b + 0] * np.exp(w) / grid_w #unit: image width\n",
        "          h = anchors[2 * b + 1] * np.exp(h) / grid_h #unit: image height\n",
        "          confidence =  netout[row, col, b,4]\n",
        "          box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
        "\n",
        "          boxes.append(box)\n",
        "\n",
        "  for c in range(nb_class):\n",
        "    sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
        "\n",
        "    for i in range(len(sorted_indices)):\n",
        "      index_i = sorted_indices[i]\n",
        "\n",
        "      if boxes[index_i].classes[c] == 0:\n",
        "        continue\n",
        "      else:\n",
        "        for j in range(i+1, len(sorted_indices)):\n",
        "          index_j = sorted_indices[j]\n",
        "          if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
        "            boxes[index_j].classes[c] = 0\n",
        "\n",
        "  #remove the boxes which are less likely than a obj_threshold\n",
        "  boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
        "\n",
        "  return boxes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mouayjhqZL6h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLO(object):\n",
        "  def __init__(self, input_size, labels, max_box_per_image, anchors):\n",
        "    self.input_size = input_size\n",
        "    self.labels = list(labels)\n",
        "    self.nb_class = len(self.labels)\n",
        "    self.nb_box = len(anchors)//2\n",
        "    self.class_wt = np.ones(self.nb_class, dtype='float32')\n",
        "    self.anchors = anchors\n",
        "    self.max_box_per_image = max_box_per_image\n",
        "\n",
        "    input_image = Input(shape=(self.input_size, self.input_size, 3))\n",
        "    self.true_boxes = Input(shape=(1, 1, 1, max_box_per_image, 4))\n",
        "\n",
        "    self.feature_extractor = FullYoloFeature(self.input_size)\n",
        "\n",
        "    print(self.feature_extractor.get_output_shape())\n",
        "    self.grid_h, self.grid_w = self.feature_extractor.get_output_shape()\n",
        "    features = self.feature_extractor.extract(input_image)\n",
        "\n",
        "\n",
        "    #make the object detection layer\n",
        "    output = Conv2D(self.nb_box * (4 + 1 + self.nb_class), (1,1), strides=(1,1), padding='same', name='DetectionLayer', kernel_initializer='lecun_normal')(features)\n",
        "    output = Reshape((self.grid_h, self.grid_w, self.nb_box, 4 + 1 + self.nb_class))(output)\n",
        "    output = Lambda(lambda args: args[0])([output, self.true_boxes])\n",
        "\n",
        "    self.model = Model([input_image, self.true_boxes], output)\n",
        "\n",
        "    #initialize the wieghts of the detection layer\n",
        "    layer = self.model.layers[-4]\n",
        "    weights = layer.get_weights()\n",
        "\n",
        "    new_kernel = np.random.normal(size=weights[0].shape)/(self.grid_h*self.grid_w)\n",
        "    new_bias = np.random.normal(size=weights[1].shape)/(self.grid_h*self.grid_w)\n",
        "\n",
        "    layer.set_weights([new_kernel, new_bias])\n",
        "\n",
        "    #print a summary of the whole model\n",
        "    self.model.summary()\n",
        "\n",
        "  def custom_loss(self, y_true, y_pred):\n",
        "   mask_shape = tf.shape(y_true)[:4]\n",
        "\n",
        "   cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(self.grid_w),[self.grid_h]),(1,self.grid_h, self.grid_w, 1, 1)))\n",
        "   cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "   cell_grid = tf.tile(tf.concat([cell_x, cell_y], -1), [self.batch_size, 1, 1, self.nb_box, 1])\n",
        "\n",
        "   coord_mask = tf.zeros(mask_shape)\n",
        "   conf_mask = tf.zeros(mask_shape)\n",
        "   class_mask = tf.zeros(mask_shape)\n",
        "\n",
        "   seen = tf.Variable(0.)\n",
        "   total_recall = tf.Variable(0.)\n",
        "\n",
        "   ###Adjust prediction\n",
        "\n",
        "   ### adjust x and y\n",
        "   pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "\n",
        "   ###adjust w and h\n",
        "   pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(self.anchors, [1,1,1,self.nb_box, 2])\n",
        "\n",
        "   ###adjust confidence\n",
        "   pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "\n",
        "   ##adjust class probabilities\n",
        "   pred_box_class = y_pred[...,5:]\n",
        "\n",
        "   ###Adjust truth\n",
        "\n",
        "   ### adjust x and y\n",
        "   true_box_xy = y_true[..., 0:2]\n",
        "\n",
        "   ### adjust w and h\n",
        "   true_box_wh = y_true[..., 2:4]\n",
        "\n",
        "   ###adjust confidence\n",
        "   true_wh_half = true_box_wh / 2.\n",
        "   true_mins = true_box_xy - true_wh_half\n",
        "   true_maxes = true_box_xy + true_wh_half\n",
        "\n",
        "   pred_wh_half = pred_box_wh / 2.\n",
        "   pred_mins = pred_box_xy - pred_wh_half\n",
        "   pred_maxes = pred_box_xy + pred_wh_half\n",
        "\n",
        "   intersect_mins = tf.maximum(pred_mins, true_mins)\n",
        "   intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "   intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "   intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "   true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "   pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "   union_areas = pred_areas + true_areas - intersect_areas\n",
        "   iou_scores = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "   true_box_conf = iou_scores * y_true[..., 4]\n",
        "\n",
        "   ### adjust class probabilities\n",
        "   true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "\n",
        "\n",
        "   ###Determine the masks\n",
        "   ##coordinate mask\n",
        "   coord_mask = tf.expand_dims(y_true[...,4], axis=-1) * self.coord_scale\n",
        "\n",
        "   ###confidence mask: penelize predictors + penelize boxes with low IOU\n",
        "   #penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "   true_xy = self.true_boxes[..., 0:2]\n",
        "   true_wh = self.true_boxes[..., 2:4]\n",
        "\n",
        "   true_wh_half = true_wh / 2.\n",
        "   true_mins = true_xy - true_wh_half\n",
        "   true_maxes = true_xy + true_wh_half\n",
        "\n",
        "   pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "   pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "\n",
        "   pred_wh_half = pred_wh / 2.\n",
        "   pred_mins = pred_xy - pred_wh_half\n",
        "   pred_maxes = pred_xy + pred_wh_half\n",
        "\n",
        "   intersect_mins = tf.maximum(pred_mins, true_mins)\n",
        "   intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "   intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "   intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "   true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "   pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\n",
        "   union_areas = pred_areas + true_areas - intersect_areas\n",
        "   iou_scores = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "   best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "   conf_max = conf_max + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * self.no_object_scale\n",
        "\n",
        "   #penalize the confidence of the boxes, which are responsibñe for sorresponding ground truth box\n",
        "   conf_mask = conf_max + y_true[..., 4] * self.object_scale\n",
        "\n",
        "   ##class mask: simply the position of the ground truth boxes ( the predictors)\n",
        "   class_mask = y_true[..., 4] * tf.gather(self.class_wt, true_box_class) * self.class_scale\n",
        "\n",
        "   ### Warm-up training\n",
        "   no_boxes_mask = tf.to_float(coord_mask < self.coord_scale/2.)\n",
        "   seen = tf.assign_add(seen, 1.)\n",
        "\n",
        "   true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, self.warmup_batches+1), lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, true_box_wh + tf.ones_like(true_box_wh) * np.reshape(self.anchors,[1,1,1,self.nb_box,2])*  no_boxes_mask, tf.ones_like(coord_mask)], lambda: [true_box_xy, true_box_wh, coord_mask])\n",
        "\n",
        "   ###Finalize the loss\n",
        "   nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "   nb_conf_box = tf.reduce_sum(tf.to_float(conf_mask > 0.0))\n",
        "   nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "\n",
        "   loss_xy = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy) * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "   loss_wh = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh) * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "   loss_conf = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask) / (nb_conf_box + 1e-6) / 2.\n",
        "   loss_class= tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "   loss_class= tf.reduce_sum(loss_class * class_mask)/(nb_class_box + 1e-6)\n",
        "   loss= tf.cond(tf.less(seen, self.warmup_batches+1), lambda: loss_xy + loss_wh + loss_conf + loss_class + 10, lambda: loss_xy + loss_wh + loss_conf + loss_class)\n",
        "   if self.debug:\n",
        "    nb_true_box = tf.reduce_sum(y_true[...,4])\n",
        "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "\n",
        "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "    total_recall = tf.assign_add(total_recall, current_recall)\n",
        "\n",
        "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\\\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\\\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\\\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_class], message='Loss Class \\\\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss], message='Total Loss \\\\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [current_recall], message='Current Recall \\\\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\\\t', summarize=1000)\n",
        "\n",
        "   return loss\n",
        "\n",
        "  def load_weights(self, weight_path):\n",
        "    self.model.load_weights(weight_path)\n",
        "\n",
        "  def train(self, train_imgs, valid_imgs, train_times, valid_times, nb_epochs, learning_rate, batch_size, warmup_epochs, object_scale, no_object_scale, coord_scale, class_scale, saved_weights_name='best_weights.h5', debug=False):\n",
        "    self.batch_size = batch_size\n",
        "    self.object_scale = object_scale\n",
        "    self.no_object_scale = no_object_scale\n",
        "    self.coord_scale = coord_scale\n",
        "    self.class_scale = class_scale\n",
        "    self.debug = debug\n",
        "    ##Make train and validation generators\n",
        "    generator_config = {\n",
        "        'IMAGE_H' : self.input_size,\n",
        "        'IMAGE_W' : self.input_size,\n",
        "        'GRID_H' : self.grid_h,\n",
        "        'GRID_W' : self.grid_w,\n",
        "        'BOX' : self.nb_box,\n",
        "        'LABELS' : self.labels,\n",
        "        'CLASS' : len(self.labels),\n",
        "        'ANCHORS' : self.anchors,\n",
        "        'BATCH_SIZE' : self.batch_size,\n",
        "        'TRUE_BOX_BUFFER' : self.max_box_per_image,\n",
        "    }\n",
        "    train_generator = BatchGenerator(train_imgs, generator_config, norm=self.feature_extractor.normalize)\n",
        "    valid_generator = BatchGenerator(valid_imgs, generator_config, norm=self.feature_extractor.normalize, jitter=False)\n",
        "    self.warmup_batches = warmup_epochs * (train_times*len(train_generator) + valid_times*len(valid_generator))\n",
        "\n",
        "    #Compile the model\n",
        "\n",
        "    optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    self.model.compile(loss=self.custom_loss, optimizer=optimizer)\n",
        "\n",
        "    #Make a few callbacks\n",
        "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
        "    checkpoint = ModelCheckpoint(saved_weights_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
        "    tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/'), histogram_freq=0, write_graph=True, write_images=False)\n",
        "    #Start the training process\n",
        "    self.model.fit_generator(generator=train_generator, steps_per_epoch=len(train_generator)*train_times, epochs=warmup_epochs + nb_epochs, verbose= 2 if debug else 1, validation_data= valid_generator, validation_steps = len(valid_generator) * valid_times, callbacks = [early_stop, checkpoint, tensorboard], workers = 3, max_queue_size = 8)\n",
        "\n",
        "    #Compute mAP on the validation set\n",
        "    average_precisions = self.evaluate(valid_generator)\n",
        "\n",
        "    #print evaluation\n",
        "    for label, average_precision in average_precisions.items():\n",
        "      print(self.labels[label], '{:.4f}'.format(average_precision))\n",
        "    print('mAP: {:.4f}'.format(sum(average_precisions.values())/len(average_precisions)))\n",
        "\n",
        "  def evaluate(self, generator, iou_threshold=0.3, score_threshold=0.3, max_detections=100, save_path=None):\n",
        "    all_detections =[[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "    all_annotations = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\n",
        "    for i in range(generator.size()):\n",
        "      raw_image = generator.load_image(i)\n",
        "      raw_height, raw_width, raw_channels = raw_image.shape\n",
        "      pred_boxes = self.predict(raw_image)\n",
        "      score = np.array([box.score for box in pred_boxes])\n",
        "      pred_labels = np.array([box.label for box in pred_boxes])\n",
        "      if len(pred_boxes) > 0:\n",
        "        pred_boxes = np.array([[box.min*raw_width, box.ymin*raw_height, box.xmax*raw_width, box.ymax*raw_height, box.score] for box in pred_boxes])\n",
        "      else:\n",
        "        pred_boxes = np.array([[]])\n",
        "\n",
        "      #sort the boxes and the labels according to score\n",
        "      score_sort = np.argsort(-score)\n",
        "      pred_labels = pred_labels[score_sort]\n",
        "      pred_boxes = pred_boxes[score_sort]\n",
        "\n",
        "      #copy detections to all_detections\n",
        "      for label in range(generator.num_classes()):\n",
        "        all_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
        "\n",
        "      annotations = generator.load_annotation(i)\n",
        "\n",
        "      #copy detections to all_annotations\n",
        "      for label in range(generator.num_classes()):\n",
        "        all_annotations[i][label] = annotations[annotations[:,4] == label, :4].copy()\n",
        "\n",
        "    average_precisions = {}\n",
        "\n",
        "    for label in range(generator.num_classes()):\n",
        "      false_positives = np.zeros((0,))\n",
        "      true_positives = np.zeros((0,))\n",
        "      scores = np.zeros((0,))\n",
        "      num_annotations = 0.0\n",
        "\n",
        "      for i in range(generator.size()):\n",
        "        detections = all_detections[i][label]\n",
        "        annotations = all_annotations[i][label]\n",
        "        num_annotations += annotations.shape[0]\n",
        "        detected_annotations = []\n",
        "\n",
        "        for d in detections:\n",
        "          scores = np.append(scores, d[4])\n",
        "          if annotations.shape[0] == 0:\n",
        "            false_positives = np.append(false_positives, 1)\n",
        "            true_positives = np.append(true_positives, 0)\n",
        "            continue\n",
        "\n",
        "          overlaps= compute_overlap(np.expand_dims(d, axis=0),annotations)\n",
        "          assigned_annotation = np.argmax(overlaps, axis=1)\n",
        "          max_overlap = overlaps[0, assigned_annotation]\n",
        "\n",
        "          if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
        "            false_positives = np.append(false_positives, 0)\n",
        "            true_positives = np.append(true_positives, 1)\n",
        "            detected_annotations.append(assigned_annotation)\n",
        "          else:\n",
        "            false_positives = np.append(false_positives, 1)\n",
        "            true_positives = np.append(true_positives, 0)\n",
        "\n",
        "      if num_annotations == 0:\n",
        "        average_precisions[label] = 0\n",
        "        continue\n",
        "\n",
        "      indices= np.argsort(-scores)\n",
        "      false_positives = false_positives[indices]\n",
        "      true_positives = true_positives[indices]\n",
        "\n",
        "      false_positives= np.cumsum(false_positives)\n",
        "      true_positives = np.cumsum(true_positives)\n",
        "\n",
        "      recall = true_positives / num_annotations\n",
        "      precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
        "\n",
        "      average_precision = compute_ap(recall, precision)\n",
        "      average_precisions[label] = average_precision\n",
        "\n",
        "    return average_precisions\n",
        "\n",
        "  def predict(self, image):\n",
        "    image_h, image_w, _ = image.shape\n",
        "    image = cv2.resize(image,(self.input_size, self.input_size))\n",
        "    image = self.feature_extractor.normalize(image)\n",
        "\n",
        "    input_image = image[:,:,::-1]\n",
        "    input_image = np.expand_dims(input_image, 0)\n",
        "    dummy_array = np.zeros((1,1,1,1,self.max_box_per_image, 4))\n",
        "\n",
        "    netout = self.model.predict([input_image, dummy_array])[0]\n",
        "    boxes = decode_netout(netout, self.anchors, self.nb_class)\n",
        "\n",
        "    return boxes\n",
        "\n"
      ],
      "metadata": {
        "id": "Qzjt8Ak20aXN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "num_anchors = 5\n",
        "def IOU(ann, centroids):\n",
        "  w, h = ann\n",
        "  similarities = []\n",
        "  for centroid in centroids:\n",
        "    c_w, c_h = centroid\n",
        "\n",
        "    if c_w >= w and c_h >=h:\n",
        "      similarity = w*h/(c_w*c_h)\n",
        "    elif c_w >= w and c_h <= h:\n",
        "      similarity = w*c_h /(w*h + (c_w-w)*c_h)\n",
        "    elif c_w <= w and c_h >= h:\n",
        "      similarity = c_w*h/(w*h + c_w*(c_h-h))\n",
        "    else:\n",
        "      similarity = (c_w*c_h)/(w*h)\n",
        "    similarities.append(similarity)\n",
        "\n",
        "  return np.array(similarities)\n",
        "\n"
      ],
      "metadata": {
        "id": "UCrfWFi20pOL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_IOU(anns, centroids):\n",
        "  n,d = anns.shape\n",
        "  sum = 0.\n",
        "  for i in range(anns.shape[0]):\n",
        "    sum+=max(IOU(anns[i], centroids))\n",
        "  return sum\n",
        "\n"
      ],
      "metadata": {
        "id": "FQwwLUiR07lr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_anchors(centroids):\n",
        "  anchors = centroids.copy()\n",
        "  widths = anchors[:,0]\n",
        "  sorted_indices = np.argsort(widths)\n",
        "  r = \"anchors:[ \"\n",
        "  for i in sorted_indices[:-1]:\n",
        "    r += '%0.2f,%0.2f, ' % (anchors[i, 0], anchors[i, 1])\n",
        "\n",
        "  r += '%0.2f,%0.2f' % (anchors[sorted_indices[-1:],0], anchors[sorted_indices[-1:],1])\n",
        "  r += \"] \"\n",
        "  print(r)\n"
      ],
      "metadata": {
        "id": "9cBtjcFH1BAa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_kmeans(ann_dims, anchor_num):\n",
        "  ann_num = ann_dims.shape[0]\n",
        "  iterations = 0\n",
        "  prev_assignments = np.ones(ann_num)*(-1)\n",
        "  iteration = 0\n",
        "  old_distances = np.zeros((ann_num, anchor_num))\n",
        "\n",
        "  indices = [random.randrange(ann_dims.shape[0]) for i in range(anchor_num)]\n",
        "  centroids = ann_dims[indices]\n",
        "  anchor_dim = ann_dims.shape[1]\n",
        "  while True:\n",
        "    distances = []\n",
        "    iteration += 1\n",
        "    for i in range(ann_num):\n",
        "      d = 1 -IOU(ann_dims[i], centroids)\n",
        "      distances.append(d)\n",
        "    distances = np.array(distances)\n",
        "    print(\"iteration {}: dists = {} \".format(iteration, np.sum(np.abs(old_distances - distances ))))\n",
        "    assignments = np.argmin(distances, axis=1)\n",
        "    if (assignments == prev_assignments).all():\n",
        "      return centroids\n",
        "    centroid_sums=np.zeros((anchor_num, anchor_dim), np.float64)\n",
        "    for i in range(ann_num):\n",
        "      centroid_sums[assignments[i]]+=ann_dims[i]\n",
        "    for j in range(anchor_num):\n",
        "      centroids[j] = centroid_sums[j]/(np.sum(assignments==j) + 1e-6)\n",
        "    prev_assignments = assignments.copy()\n",
        "    old_distances = distances.copy()\n"
      ],
      "metadata": {
        "id": "RoA6U8G-1FRC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grid_w = tamanio/32\n",
        "grid_h = tamanio/32\n",
        "\n",
        "annotation_dims = []\n",
        "for  image  in train_imgs:\n",
        "  cell_w= image['width']//grid_w\n",
        "  cell_h = image['height']/grid_h\n",
        "  for obj in image['object']:\n",
        "   relative_w = (float(obj['xmax']) - float(obj['xmin']))/cell_w\n",
        "   relatice_h = (float(obj['ymax']) - float(obj['ymin']))/cell_h\n",
        "   annotation_dims.append(tuple(map(float, (relative_w, relatice_h))))\n",
        "\n"
      ],
      "metadata": {
        "id": "24YomBg91JHD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "annotation_dims = np.array(annotation_dims)\n",
        "centroids = run_kmeans(annotation_dims, num_anchors)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeCI0muZ1Lpa",
        "outputId": "3282849c-5087-40bf-bd29-9444408cff83"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 1: dists = 861.6156120753275 \n",
            "iteration 2: dists = 49.92862825713934 \n",
            "iteration 3: dists = 18.736136242011156 \n",
            "iteration 4: dists = 13.500384273258343 \n",
            "iteration 5: dists = 8.236619473865307 \n",
            "iteration 6: dists = 12.394855159008914 \n",
            "iteration 7: dists = 14.75530637600686 \n",
            "iteration 8: dists = 12.968150562687843 \n",
            "iteration 9: dists = 10.251430110477171 \n",
            "iteration 10: dists = 8.394219191833201 \n",
            "iteration 11: dists = 4.878622390006939 \n",
            "iteration 12: dists = 4.352724459066243 \n",
            "iteration 13: dists = 1.4394601616230105 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\\\naverage IOU for', num_anchors, 'anchors:', '%0.2f' % avg_IOU(annotation_dims, centroids))\n",
        "print_anchors(centroids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az2xf1qU1RJS",
        "outputId": "fc9b1e3b-820e-49d1-e469-a449f6a1d418"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\naverage IOU for 5 anchors: 229.70\n",
            "anchors:[ 2.07,2.82, 2.74,4.88, 4.19,5.76, 5.50,8.96, 8.29,11.16] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-db8f7bd6c1c7>:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  r += '%0.2f,%0.2f' % (anchors[sorted_indices[-1:],0], anchors[sorted_indices[-1:],1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "anchors=[]\n",
        "for x in centroids:\n",
        "  anchors.append(x[0])\n",
        "  anchors.append(x[1])\n",
        "anchors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wtl2jLmP1Vwz",
        "outputId": "0a36d23d-2e86-4a33-c5c9-effd9f72f6a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.504406625309964,\n",
              " 8.961627597837541,\n",
              " 4.188897324517417,\n",
              " 5.760529233187396,\n",
              " 2.0717462480132363,\n",
              " 2.8237844514241366,\n",
              " 2.7405251273289344,\n",
              " 4.882212756899107,\n",
              " 8.294834529116873,\n",
              " 11.164671556405155]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#instaciamos el modelo\n",
        "yolo = YOLO(input_size=tamanio, labels = labels, max_box_per_image = 5, anchors=anchors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "wT7B6NYr1ZED",
        "outputId": "d78f0ba3-5449-403b-b47b-a7f293776f94"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The layer model has never been called and thus has no defined output shape.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-46444bb5aca9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#instaciamos el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myolo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtamanio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_box_per_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-c39042cfb8d1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, labels, max_box_per_image, anchors)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullYoloFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1a5e1abab06a>\u001b[0m in \u001b[0;36mget_output_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m          \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m        \u001b[0;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36mget_output_shape_at\u001b[0;34m(self, node_index)\u001b[0m\n\u001b[1;32m   2013\u001b[0m           \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mEager\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \"\"\"\n\u001b[0;32m-> 2015\u001b[0;31m         return self._get_node_attribute_at_index(\n\u001b[0m\u001b[1;32m   2016\u001b[0m             \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output shape\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m   2976\u001b[0m         \"\"\"\n\u001b[1;32m   2977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2978\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2979\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2980\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The layer model has never been called and thus has no defined output shape."
          ]
        }
      ]
    }
  ]
}